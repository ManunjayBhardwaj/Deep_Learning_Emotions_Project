{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c84a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label Mapping:\n",
      "NEGATIVE → 0\n",
      "NEUTRAL → 1\n",
      "POSITIVE → 2\n",
      "Epoch 1/40 | Loss: 27.3493 | Accuracy: 0.8194\n",
      "Epoch 2/40 | Loss: 8.0683 | Accuracy: 0.9402\n",
      "Epoch 3/40 | Loss: 4.3506 | Accuracy: 0.9701\n",
      "Epoch 4/40 | Loss: 1.3628 | Accuracy: 0.9906\n",
      "Epoch 5/40 | Loss: 1.0058 | Accuracy: 0.9947\n",
      "Epoch 6/40 | Loss: 1.2619 | Accuracy: 0.9953\n",
      "Epoch 7/40 | Loss: 0.7281 | Accuracy: 0.9965\n",
      "Epoch 8/40 | Loss: 0.9949 | Accuracy: 0.9971\n",
      "Epoch 9/40 | Loss: 0.8614 | Accuracy: 0.9953\n",
      "Epoch 10/40 | Loss: 0.5500 | Accuracy: 0.9971\n",
      "Epoch 11/40 | Loss: 0.3641 | Accuracy: 0.9982\n",
      "Epoch 12/40 | Loss: 2.8043 | Accuracy: 0.9842\n",
      "Epoch 13/40 | Loss: 1.1589 | Accuracy: 0.9947\n",
      "Epoch 14/40 | Loss: 0.3119 | Accuracy: 0.9988\n",
      "Epoch 15/40 | Loss: 0.8301 | Accuracy: 0.9953\n",
      "Epoch 16/40 | Loss: 0.9585 | Accuracy: 0.9971\n",
      "Epoch 17/40 | Loss: 0.8163 | Accuracy: 0.9959\n",
      "Epoch 18/40 | Loss: 1.0623 | Accuracy: 0.9941\n",
      "Epoch 19/40 | Loss: 0.7919 | Accuracy: 0.9953\n",
      "Epoch 20/40 | Loss: 0.1268 | Accuracy: 1.0000\n",
      "Epoch 21/40 | Loss: 0.1024 | Accuracy: 0.9994\n",
      "Epoch 22/40 | Loss: 0.1464 | Accuracy: 0.9988\n",
      "Epoch 23/40 | Loss: 0.2537 | Accuracy: 0.9988\n",
      "Epoch 24/40 | Loss: 0.0456 | Accuracy: 1.0000\n",
      "Epoch 25/40 | Loss: 0.0158 | Accuracy: 1.0000\n",
      "Epoch 26/40 | Loss: 0.0994 | Accuracy: 0.9994\n",
      "Epoch 27/40 | Loss: 0.3025 | Accuracy: 0.9994\n",
      "Epoch 28/40 | Loss: 0.3319 | Accuracy: 0.9988\n",
      "Epoch 29/40 | Loss: 0.0332 | Accuracy: 1.0000\n",
      "Epoch 30/40 | Loss: 0.0163 | Accuracy: 1.0000\n",
      "Epoch 31/40 | Loss: 0.0125 | Accuracy: 1.0000\n",
      "Epoch 32/40 | Loss: 0.7978 | Accuracy: 0.9988\n",
      "Epoch 33/40 | Loss: 0.3223 | Accuracy: 0.9982\n",
      "Epoch 34/40 | Loss: 0.1732 | Accuracy: 0.9988\n",
      "Epoch 35/40 | Loss: 0.2233 | Accuracy: 0.9988\n",
      "Epoch 36/40 | Loss: 0.1081 | Accuracy: 0.9994\n",
      "Epoch 37/40 | Loss: 0.0480 | Accuracy: 1.0000\n",
      "Epoch 38/40 | Loss: 0.0223 | Accuracy: 1.0000\n",
      "Epoch 39/40 | Loss: 0.0869 | Accuracy: 0.9988\n",
      "Epoch 40/40 | Loss: 0.1974 | Accuracy: 0.9994\n",
      "\n",
      "Test Accuracy: 0.9742\n",
      "\n",
      "Hybrid model + scaler + label encoder saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import joblib\n",
    "\n",
    "# ============================================================\n",
    "# 1. LOAD DATA\n",
    "# ============================================================\n",
    "df = pd.read_csv(\"emotions.csv\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. CLEANING\n",
    "# ============================================================\n",
    "df = df.drop_duplicates()\n",
    "df = df.dropna(subset=[\"label\"])\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
    "\n",
    "# ============================================================\n",
    "# 3. FEATURE SPLITTING\n",
    "# ============================================================\n",
    "\n",
    "# Identify LSTM sequential FFT features\n",
    "seq_cols = [c for c in df.columns if \"fft_\" in c]\n",
    "\n",
    "# Identify ANN statistical features\n",
    "stat_cols = [c for c in df.columns if c not in seq_cols + [\"label\"]]\n",
    "\n",
    "X_seq = df[seq_cols]           # shape → (N, 750)\n",
    "X_stat = df[stat_cols]         # shape → (N, num_stats)\n",
    "\n",
    "y = df[\"label\"]\n",
    "\n",
    "# ============================================================\n",
    "# 4. LABEL ENCODING\n",
    "# ============================================================\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "print(\"\\nLabel Mapping:\")\n",
    "for i, c in enumerate(label_encoder.classes_):\n",
    "    print(f\"{c} → {i}\")\n",
    "\n",
    "# ============================================================\n",
    "# 5. TRAIN–TEST SPLIT\n",
    "# ============================================================\n",
    "X_seq_train, X_seq_test, X_stat_train, X_stat_test, y_train, y_test = train_train_test_split = train_test_split(\n",
    "    X_seq, X_stat, y_encoded,\n",
    "    test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 6. SCALING (only statistical features)\n",
    "# ============================================================\n",
    "stat_scaler = StandardScaler()\n",
    "X_stat_train = stat_scaler.fit_transform(X_stat_train)\n",
    "X_stat_test = stat_scaler.transform(X_stat_test)\n",
    "\n",
    "# Convert to float32 numpy\n",
    "X_seq_train = X_seq_train.to_numpy().astype(np.float32)\n",
    "X_seq_test = X_seq_test.to_numpy().astype(np.float32)\n",
    "\n",
    "# Reshape FFT data for LSTM → (batch, seq_len, features)\n",
    "X_seq_train = X_seq_train.reshape(len(X_seq_train), len(seq_cols), 1)\n",
    "X_seq_test = X_seq_test.reshape(len(X_seq_test), len(seq_cols), 1)\n",
    "\n",
    "X_stat_train = X_stat_train.astype(np.float32)\n",
    "X_stat_test = X_stat_test.astype(np.float32)\n",
    "\n",
    "y_train = np.array(y_train, dtype=np.int64)\n",
    "y_test = np.array(y_test, dtype=np.int64)\n",
    "\n",
    "# ============================================================\n",
    "# 7. DATASET & DATA LOADER\n",
    "# ============================================================\n",
    "class HybridDataset(Dataset):\n",
    "    def __init__(self, X_seq, X_stat, y):\n",
    "        self.X_seq = torch.tensor(X_seq, dtype=torch.float32)\n",
    "        self.X_stat = torch.tensor(X_stat, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_seq[idx], self.X_stat[idx], self.y[idx]\n",
    "\n",
    "train_dataset = HybridDataset(X_seq_train, X_stat_train, y_train)\n",
    "test_dataset = HybridDataset(X_seq_test, X_stat_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# ============================================================\n",
    "# 8. HYBRID LSTM + ANN MODEL\n",
    "# ============================================================\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, seq_len, stat_dim, num_classes):\n",
    "        super(HybridModel, self).__init__()\n",
    "\n",
    "        # ---- LSTM BRANCH ----\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=1,\n",
    "            hidden_size=64,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=0.3,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        self.lstm_fc = nn.Linear(64 * 2, 128)  # BiLSTM → 128\n",
    "\n",
    "        # ---- ANN BRANCH ----\n",
    "        self.ann = nn.Sequential(\n",
    "            nn.Linear(stat_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "        # ---- COMBINED CLASSIFIER ----\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128 + 64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, seq_input, stat_input):\n",
    "        # LSTM branch\n",
    "        lstm_out, _ = self.lstm(seq_input)\n",
    "        lstm_last = lstm_out[:, -1, :]          # last timestep\n",
    "        lstm_feat = self.lstm_fc(lstm_last)\n",
    "\n",
    "        # ANN branch\n",
    "        ann_feat = self.ann(stat_input)\n",
    "\n",
    "        # Concatenate\n",
    "        combined = torch.cat([lstm_feat, ann_feat], dim=1)\n",
    "\n",
    "        # Classification\n",
    "        out = self.classifier(combined)\n",
    "        return out\n",
    "\n",
    "# ============================================================\n",
    "# 9. TRAINING SETUP\n",
    "# ============================================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = HybridModel(\n",
    "    seq_len=len(seq_cols),\n",
    "    stat_dim=len(stat_cols),\n",
    "    num_classes=len(label_encoder.classes_)\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ============================================================\n",
    "# 10. TRAINING LOOP\n",
    "# ============================================================\n",
    "epochs = 40\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    for seq_batch, stat_batch, y_batch in train_loader:\n",
    "        seq_batch, stat_batch, y_batch = seq_batch.to(device), stat_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(seq_batch, stat_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == y_batch).sum().item()\n",
    "\n",
    "    acc = correct / len(train_dataset)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Loss: {total_loss:.4f} | Accuracy: {acc:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 11. TESTING\n",
    "# ============================================================\n",
    "model.eval()\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for seq_batch, stat_batch, y_batch in test_loader:\n",
    "        seq_batch, stat_batch, y_batch = seq_batch.to(device), stat_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        outputs = model(seq_batch, stat_batch)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == y_batch).sum().item()\n",
    "\n",
    "test_acc = correct / len(test_dataset)\n",
    "print(f\"\\nTest Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 12. SAVE EVERYTHING\n",
    "# ============================================================\n",
    "torch.save(model.state_dict(), \"hybrid_lstm_ann.pth\")\n",
    "joblib.dump(stat_scaler, \"stat_scaler.pkl\")\n",
    "joblib.dump(label_encoder, \"label_encoder.pkl\")\n",
    "\n",
    "print(\"\\nHybrid model + scaler + label encoder saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "583ac461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># mean_0_a</th>\n",
       "      <th>mean_1_a</th>\n",
       "      <th>mean_2_a</th>\n",
       "      <th>mean_3_a</th>\n",
       "      <th>mean_4_a</th>\n",
       "      <th>mean_d_0_a</th>\n",
       "      <th>mean_d_1_a</th>\n",
       "      <th>mean_d_2_a</th>\n",
       "      <th>mean_d_3_a</th>\n",
       "      <th>mean_d_4_a</th>\n",
       "      <th>...</th>\n",
       "      <th>fft_741_b</th>\n",
       "      <th>fft_742_b</th>\n",
       "      <th>fft_743_b</th>\n",
       "      <th>fft_744_b</th>\n",
       "      <th>fft_745_b</th>\n",
       "      <th>fft_746_b</th>\n",
       "      <th>fft_747_b</th>\n",
       "      <th>fft_748_b</th>\n",
       "      <th>fft_749_b</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.62</td>\n",
       "      <td>30.3</td>\n",
       "      <td>-356.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>26.3</td>\n",
       "      <td>1.070</td>\n",
       "      <td>0.411</td>\n",
       "      <td>-15.70</td>\n",
       "      <td>2.06</td>\n",
       "      <td>3.15</td>\n",
       "      <td>...</td>\n",
       "      <td>23.5</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.3</td>\n",
       "      <td>23.5</td>\n",
       "      <td>-215.0</td>\n",
       "      <td>280.00</td>\n",
       "      <td>-162.00</td>\n",
       "      <td>-162.00</td>\n",
       "      <td>280.00</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.80</td>\n",
       "      <td>33.1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>22.8</td>\n",
       "      <td>6.550</td>\n",
       "      <td>1.680</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3.83</td>\n",
       "      <td>-4.82</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.3</td>\n",
       "      <td>-21.8</td>\n",
       "      <td>-21.8</td>\n",
       "      <td>-23.3</td>\n",
       "      <td>182.0</td>\n",
       "      <td>2.57</td>\n",
       "      <td>-31.60</td>\n",
       "      <td>-31.60</td>\n",
       "      <td>2.57</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.90</td>\n",
       "      <td>29.4</td>\n",
       "      <td>-416.0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>23.7</td>\n",
       "      <td>79.900</td>\n",
       "      <td>3.360</td>\n",
       "      <td>90.20</td>\n",
       "      <td>89.90</td>\n",
       "      <td>2.03</td>\n",
       "      <td>...</td>\n",
       "      <td>462.0</td>\n",
       "      <td>-233.0</td>\n",
       "      <td>-233.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>-267.0</td>\n",
       "      <td>281.00</td>\n",
       "      <td>-148.00</td>\n",
       "      <td>-148.00</td>\n",
       "      <td>281.00</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.90</td>\n",
       "      <td>31.6</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>19.8</td>\n",
       "      <td>24.3</td>\n",
       "      <td>-0.584</td>\n",
       "      <td>-0.284</td>\n",
       "      <td>8.82</td>\n",
       "      <td>2.30</td>\n",
       "      <td>-1.97</td>\n",
       "      <td>...</td>\n",
       "      <td>299.0</td>\n",
       "      <td>-243.0</td>\n",
       "      <td>-243.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>-12.40</td>\n",
       "      <td>9.53</td>\n",
       "      <td>9.53</td>\n",
       "      <td>-12.40</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.30</td>\n",
       "      <td>31.3</td>\n",
       "      <td>45.2</td>\n",
       "      <td>27.3</td>\n",
       "      <td>24.5</td>\n",
       "      <td>34.800</td>\n",
       "      <td>-5.790</td>\n",
       "      <td>3.06</td>\n",
       "      <td>41.40</td>\n",
       "      <td>5.52</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>38.1</td>\n",
       "      <td>38.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>-17.60</td>\n",
       "      <td>23.90</td>\n",
       "      <td>23.90</td>\n",
       "      <td>-17.60</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2549 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   # mean_0_a  mean_1_a  mean_2_a  mean_3_a  mean_4_a  mean_d_0_a  mean_d_1_a  \\\n",
       "0        4.62      30.3    -356.0      15.6      26.3       1.070       0.411   \n",
       "1       28.80      33.1      32.0      25.8      22.8       6.550       1.680   \n",
       "2        8.90      29.4    -416.0      16.7      23.7      79.900       3.360   \n",
       "3       14.90      31.6    -143.0      19.8      24.3      -0.584      -0.284   \n",
       "4       28.30      31.3      45.2      27.3      24.5      34.800      -5.790   \n",
       "\n",
       "   mean_d_2_a  mean_d_3_a  mean_d_4_a  ...  fft_741_b  fft_742_b  fft_743_b  \\\n",
       "0      -15.70        2.06        3.15  ...       23.5       20.3       20.3   \n",
       "1        2.88        3.83       -4.82  ...      -23.3      -21.8      -21.8   \n",
       "2       90.20       89.90        2.03  ...      462.0     -233.0     -233.0   \n",
       "3        8.82        2.30       -1.97  ...      299.0     -243.0     -243.0   \n",
       "4        3.06       41.40        5.52  ...       12.0       38.1       38.1   \n",
       "\n",
       "   fft_744_b  fft_745_b  fft_746_b  fft_747_b  fft_748_b  fft_749_b     label  \n",
       "0       23.5     -215.0     280.00    -162.00    -162.00     280.00  NEGATIVE  \n",
       "1      -23.3      182.0       2.57     -31.60     -31.60       2.57   NEUTRAL  \n",
       "2      462.0     -267.0     281.00    -148.00    -148.00     281.00  POSITIVE  \n",
       "3      299.0      132.0     -12.40       9.53       9.53     -12.40  POSITIVE  \n",
       "4       12.0      119.0     -17.60      23.90      23.90     -17.60   NEUTRAL  \n",
       "\n",
       "[5 rows x 2549 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1=pd.read_csv('emotions.csv')\n",
    "df1.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
